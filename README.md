# DEFLANDRE NASSIM 

# The Book AI

Une plateforme web moderne pour gÃ©nÃ©rer des histoires personnalisÃ©es pour enfants alimentÃ©e par l'intelligence artificielle. 

## ğŸ“‹ Table of Contents

- [Presentation du projet](#PrÃ©sentation-du-projet)
- [Stack Technique](#stack-technique)
- [Architecture](#architecture)
- [PrÃ©requis](#prÃ©requis)
- [Installation](#installation)
- [Structure du Projet](#structure-du-projet)
- [Configuration](#configuration)

## PrÃ©sentation du projet

**The Book AI** est une application web qui permet aux utilisateurs de crÃ©er des histoires originales et personnalisÃ©es pour enfants grÃ¢ce Ã  une intelligence artificielle gÃ©nÃ©rative. La plateforme permet de configurer diffÃ©rents paramÃ¨tres (thÃ¨me, personnages, longueur, moral de l'histoire, etc.) pour gÃ©nÃ©rer des contes uniques et adaptÃ©s Ã  chaque enfant.

### FonctionnalitÃ©s principales

- âœ¨ GÃ©nÃ©ration d'histoires IA personnalisÃ©es
- ğŸ¨ Interface utilisateur intuitive et moderne
- âš¡ Traitement rapide et efficace
- ğŸ” Architecture sÃ©curisÃ©e

## Stack Technique

### Backend
- **Java Spring Boot** - Framework web et API REST
- **Maven** - Gestionnaire de dÃ©pendances et build
- **PostgreSQL** - Base de donnÃ©es relationnelle

### Frontend
- **Nuxt.js** - Framework Vue.js pour SSR et SSG
- **TypeScript** - Typage statique JavaScript

### IA & LLM
- **Ollama** - Moteur LLM local pour la gÃ©nÃ©ration d'histoires

### DevOps
- **Docker & Docker Compose** - Containerisation et orchestration
- **Caddy** - Serveur reverse proxy

## Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         Frontend - Nuxt.js (Port 3000)          â”‚
â”‚              Interface Utilisateur               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          Caddy Reverse Proxy (Port 80)          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     Backend - Spring Boot (Port 8080)           â”‚
â”‚            REST API & Business Logic            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                          â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   PostgreSQL     â”‚     â”‚  Ollama LLM     â”‚
â”‚  (Port 5432)     â”‚     â”‚  (Port 11434)   â”‚
â”‚  Base de donnÃ©es â”‚     â”‚ GÃ©nÃ©ration IA   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## PrÃ©requis

- Docker & Docker Compose (v20.10+)
- Java 17+ (pour le dÃ©veloppement local)
- Node.js 18+ (pour le dÃ©veloppement frontend)
- 4GB RAM minimum
- 10GB espace disque (pour Ollama)

## Installation

### Avec Docker Compose (RecommandÃ©)

```bash
# Cloner le repository
git clone <repository-url>
cd the-book-ai

# DÃ©marrer l'application complÃ¨te
docker compose up --build -d

# VÃ©rifier les logs
docker compose logs -f
```

L'application sera accessible via :
- Frontend: http://localhost
- API: http://localhost/api
- PostgreSQL: localhost:5432
- Ollama: localhost:11434

### DÃ©veloppement Local

#### Backend (Spring Boot)

```bash
cd api-book

# Compiler
./mvnw clean package

# DÃ©marrer l'application
./mvnw spring-boot:run

# Avec profil local
./mvnw spring-boot:run -Dspring-boot.run.arguments="--spring.profiles.active=local"
```

## Configuration

### Variables d'Environnement

#### Backend ajouter coter api (api-book/src/main/resources/application-local.yml)

```yaml
spring:
  datasource:
    url: jdbc:postgresql://db:5432/book_ai
    username: votre-user
    password: votre-password
  jpa:
    hibernate:
      ddl-auto: update

ollama:
  api-url: http://ollama:11434
  model: mistral  # ou autre modÃ¨le compatible


# Docker Desktop Container

![Logo du projet](images/docker-container.png)
 
## Commandes Docker Utiles

```bash
# DÃ©marrer les services
docker compose up -d

# Ce projet utilise un Quick Tunnel gratuit (trycloudflare) : lâ€™URL est temporaire et change Ã  chaque redÃ©marrage.

# DÃ©marrer cloudflared :
docker compose --profile tunnel up -d cloudflared

# RÃ©cupÃ©rer lâ€™URL publique :
docker logs pandemic-cloudflared --tail 40

# ArrÃªter les services
docker compose down

# Voir les logs
docker compose logs -f <service-name>


```

# MÃ©thodologie & Transparence IA

- claude code 
- vs code front 
- intellinJ Api


# DifficultÃ© rencontrÃ©s : 

- La mise en place de cloudFlare avec Caddyfile. J'ai du faire quelque recherche car je n'ai jamais mis en place un tunnel. 






